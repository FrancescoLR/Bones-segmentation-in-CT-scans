{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Conv2D, Convolution2D, MaxPooling2D, BatchNormalization, UpSampling2D, Conv2DTranspose , Dropout, Permute, Reshape, Activation, concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.constraints import max_norm\n",
    "from keras import metrics\n",
    "from keras.models import load_model\n",
    "\n",
    "import os\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "K.set_image_data_format('channels_last') #Tensorflow ordering data\n",
    "img_rows = 512\n",
    "img_cols = 512\n",
    "smooth = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def get_unet():\n",
    "    \n",
    "    inputs = Input((img_rows, img_cols,1))\n",
    "    conv1 = Conv2D(16, (3, 3), padding=\"same\",kernel_constraint=max_norm(4.))(inputs)\n",
    "    norm1 = BatchNormalization(axis=3)(conv1)\n",
    "    act1 = Activation(\"relu\")(norm1)\n",
    "    drop1 = Dropout(0.4) (act1)\n",
    "    conv1 = Conv2D(16, (3, 3), padding=\"same\",kernel_constraint=max_norm(4.))(drop1)\n",
    "    norm1 = BatchNormalization(axis=3)(conv1)\n",
    "    act1 = Activation(\"relu\")(norm1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(act1)\n",
    "    \n",
    "    \n",
    "    conv2 = Conv2D(32, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(pool1)\n",
    "    norm2 = BatchNormalization(axis=3)(conv2)\n",
    "    act2 = Activation(\"relu\")(norm2)\n",
    "    drop2 = Dropout(0.4)(act2)\n",
    "    conv2 = Conv2D(32, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(drop2)\n",
    "    norm2 = BatchNormalization(axis=3)(conv2)\n",
    "    act2 = Activation(\"relu\")(norm2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(act2)\n",
    "    conv3 = Conv2D(64, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(pool2)\n",
    "    norm3 = BatchNormalization(axis=3)(conv3)\n",
    "    act3 = Activation(\"relu\")(norm3)\n",
    "    drop3 = Dropout(0.4)(act3)\n",
    "    conv3 = Conv2D(64, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(drop3)\n",
    "    norm3 = BatchNormalization(axis=3)(conv3)\n",
    "    act3 = Activation(\"relu\")(norm3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(act3)\n",
    "    conv4 = Conv2D(128, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(pool3)\n",
    "    norm4 = BatchNormalization(axis=3)(conv4)\n",
    "    act4 = Activation(\"relu\")(norm4)\n",
    "    drop4 = Dropout(0.4)(act4)\n",
    "    conv4 = Conv2D(128, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(drop4)\n",
    "    norm4 = BatchNormalization(axis=3)(conv4)\n",
    "    act4 = Activation(\"relu\")(norm4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(act4)\n",
    "    conv5 = Conv2D(256, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(pool4)\n",
    "    norm5 = BatchNormalization(axis=3)(conv5)\n",
    "    act5 = Activation(\"relu\")(norm5)\n",
    "    drop5 = Dropout(0.4)(act5)\n",
    "    conv5 = Conv2D(256, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(drop5)\n",
    "    norm5 = BatchNormalization(axis=3)(conv5)\n",
    "    act5 = Activation(\"relu\")(norm5)\n",
    "    \n",
    "    up6 = concatenate([Conv2DTranspose(128,(2, 2), strides =(2,2),padding=\"same\")(act5), act4], axis=3)\n",
    "    conv6 = Conv2D(128, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(up6)\n",
    "    norm6 = BatchNormalization(axis=3)(conv6)\n",
    "    act6 = Activation(\"relu\")(norm6)\n",
    "    drop6 = Dropout(0.4)(act6)\n",
    "    conv6 = Conv2D(128, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(drop6)\n",
    "    norm6 = BatchNormalization(axis=3)(conv6)\n",
    "    act6 = Activation(\"relu\")(norm6)\n",
    "    up7 = concatenate([Conv2DTranspose(64,(2, 2), strides =(2,2),padding=\"same\")(act6), act3], axis=3)\n",
    "    conv7 = Conv2D(64, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(up7)\n",
    "    norm7 = BatchNormalization(axis=3)(conv7)\n",
    "    act7 = Activation(\"relu\")(norm7)\n",
    "    drop7 = Dropout(0.4)(act7)\n",
    "    conv7 = Conv2D(64, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(drop7)\n",
    "    norm7 = BatchNormalization(axis=3)(conv7)\n",
    "    act7 = Activation(\"relu\")(norm7)\n",
    "    up8 = concatenate([Conv2DTranspose(32,(2, 2), strides =(2,2),padding=\"same\")(act7), act2], axis=3)\n",
    "    conv8 = Conv2D(32, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(up8)\n",
    "    norm8 = BatchNormalization(axis=3)(conv8)\n",
    "    act8 = Activation(\"relu\")(norm8)\n",
    "    drop8 = Dropout(0.4)(act8)\n",
    "    conv8 = Conv2D(32, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(drop8)\n",
    "    norm8 = BatchNormalization(axis=3)(conv8)\n",
    "    act8 = Activation(\"relu\")(norm8)\n",
    "    up9 = concatenate([Conv2DTranspose(16,(2, 2), strides =(2,2),padding=\"same\")(act8), act1], axis=3)\n",
    "    conv9 = Conv2D(16, (3, 3), padding=\"same\", kernel_constraint=max_norm(4.))(up9)\n",
    "    norm9 = BatchNormalization(axis=3)(conv9)\n",
    "    act9 = Activation(\"relu\")(norm9)\n",
    "    drop9 = Dropout(0.4)(act9)\n",
    "    conv9 = Conv2D(16, (3, 3), padding=\"same\",kernel_constraint=max_norm(4.))(drop9)\n",
    "    norm9 = BatchNormalization(axis=3)(conv9)\n",
    "    act9 = Activation(\"relu\")(norm9)\n",
    "    conv10 = Conv2D(7, (1, 1), activation='linear')(act9)\n",
    "    \n",
    "    flat = Reshape((img_rows*img_cols,7))(conv10)\n",
    "    soft = Activation(\"softmax\")(flat)\n",
    "    model = Model(inputs=[inputs], outputs=[soft])\n",
    "    model.compile(optimizer=Adam(lr=1e-4 ,decay=1e-7), loss=loss_function, metrics=[dice_coef])\n",
    "    #model.compile(optimizer=SGD(lr=1e-1, decay=1e-3, momentum=0.90, nesterov=True), loss=loss_function, metrics=[dice_coef])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def loss_function(y_true,y_pred):\n",
    "    y_true_f = K.reshape(y_true,(4*512*512,7))\n",
    "    y_pred_f = K.reshape(y_pred,(4*512*512,7))\n",
    "    \n",
    "    class_back = K.constant(1,shape=[8*512*512,1])\n",
    "    class_bone = K.constant(200,shape=[8*512*512,6])\n",
    "    class_weight = K.concatenate((class_back,class_bone))\n",
    "    \n",
    "    \n",
    "    weight_map = y_true_f*class_weight\n",
    "    weight_map = K.sum(weight_map, axis=1)\n",
    "    \n",
    "    loss_map = K.categorical_crossentropy(y_pred_f, y_true_f,from_logits=False) #change if softmax is present or not in the net\n",
    "    weighted_loss = loss_map*weight_map\n",
    "    \n",
    "    loss=K.mean(weighted_loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def loss_function(y_true,y_pred):\n",
    "    y_true_f = K.reshape(y_true,(8*512*512,7))\n",
    "    y_pred_f = K.reshape(y_pred,(8*512*512,7))\n",
    "    \n",
    "    class_back = K.constant(0.98,shape=[8*512*512,1])\n",
    "    class_bone = K.constant(102.,shape=[8*512*512,1])\n",
    "    class_weight = K.concatenate((class_back,class_bone))\n",
    "    \n",
    "    class_bone = K.constant(54.,shape=[8*512*512,1])\n",
    "    class_w = K.concatenate((class_weight,class_bone))\n",
    "    \n",
    "    class_bone = K.constant(403.,shape=[8*512*512,1])\n",
    "    class_w = K.concatenate((class_w,class_bone))\n",
    "    \n",
    "    class_bone = K.constant(134.,shape=[8*512*512,1])\n",
    "    class_w = K.concatenate((class_w,class_bone))\n",
    "    \n",
    "    class_bone = K.constant(100.,shape=[8*512*512,1])\n",
    "    class_w = K.concatenate((class_w,class_bone))\n",
    "    \n",
    "    class_bone = K.constant(54.,shape=[8*512*512,1])\n",
    "    class_weight = K.concatenate((class_w,class_bone))\n",
    "    \n",
    "    weight_map = y_true_f*class_weight\n",
    "    weight_map = K.sum(weight_map, axis=1)\n",
    "    \n",
    "    \n",
    "    loss_map = K.categorical_crossentropy(y_pred_f, y_true_f,from_logits=False) #change if softmax is present or not in the net\n",
    "    weighted_loss = loss_map*weight_map\n",
    "    \n",
    "    loss=K.mean(weighted_loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    \n",
    "    y_true = K.reshape(y_true,(8*512*512,7))\n",
    "    y_pred = K.reshape(y_pred,(8*512*512,7))\n",
    "    \n",
    "    y_true_back = y_true[:,0]\n",
    "    y_pred_back= y_pred[:,0]\n",
    "    intersection_back= K.sum(y_true_back * y_pred_back)\n",
    "    back = (2. * intersection_back + smooth) / (K.sum(y_true_back) + K.sum(y_pred_back) + smooth)\n",
    "    \n",
    "    \n",
    "    y_true_spine = y_true[:,1]\n",
    "    y_pred_spine= y_pred[:,1]\n",
    "    #y_pred_spine = K.greater(y_pred_spine, 0.99)\n",
    "    #y_pred_spine = K.cast(y_pred_spine,\"float32\")\n",
    "    intersection_spine= K.sum(y_true_spine * y_pred_spine)\n",
    "    spine = (2. * intersection_spine + smooth) / (K.sum(y_true_spine) + K.sum(y_pred_spine) + smooth)\n",
    "    \n",
    "    y_true_hips = y_true[:,2]\n",
    "    y_pred_hips= y_pred[:,2]\n",
    "    intersection_hips= K.sum(y_true_hips * y_pred_hips)\n",
    "    hips = (2. * intersection_hips + smooth) / (K.sum(y_true_hips) + K.sum(y_pred_hips) + smooth)\n",
    "    \n",
    "    y_true_sternum = y_true[:,3]\n",
    "    y_pred_sternum= y_pred[:,3]\n",
    "    intersection_sternum= K.sum(y_true_sternum * y_pred_sternum)\n",
    "    sternum = (2. * intersection_sternum + smooth) / (K.sum(y_true_sternum)+ K.sum(y_pred_sternum) + smooth)\n",
    "    \n",
    "    y_true_ribs = y_true[:,4]\n",
    "    y_pred_ribs= y_pred[:,4]\n",
    "    intersection_ribs= K.sum(y_true_ribs * y_pred_ribs)\n",
    "    ribs = (2. * intersection_ribs + smooth) / (K.sum(y_true_ribs) + K.sum(y_pred_ribs) + smooth)\n",
    "    \n",
    "    y_true_sacrum = y_true[:,5]\n",
    "    y_pred_sacrum= y_pred[:,5]\n",
    "    intersection_sacrum= K.sum(y_true_sacrum * y_pred_sacrum)\n",
    "    sacrum = (2. * intersection_sacrum + smooth) / (K.sum(y_true_sacrum) + K.sum(y_pred_sacrum) + smooth)\n",
    "    \n",
    "    y_true_femur = y_true[:,6]\n",
    "    y_pred_femur= y_pred[:,6]\n",
    "    intersection_femur= K.sum(y_true_femur * y_pred_femur)\n",
    "    femur = (2. * intersection_femur + smooth) / (K.sum(y_true_femur) + K.sum(y_pred_femur) + smooth)\n",
    "    \n",
    "    acc_spine = (intersection_spine / K.sum(y_true_spine))\n",
    "    acc_sternum = (intersection_sternum / K.sum(y_true_sternum))\n",
    "    acc_back = (intersection_back / K.sum(y_true_back))\n",
    "    acc_ribs = (intersection_ribs / K.sum(y_true_ribs))\n",
    "    \n",
    "    \n",
    "    return (back+hips+sacrum+spine+ribs+sternum+femur)/ 7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef_back(y_true, y_pred):\n",
    "    \n",
    "    y_true = K.reshape(y_true,(8*512*512,7))\n",
    "    y_pred = K.reshape(y_pred,(8*512*512,7))\n",
    "    \n",
    "    y_true_back = y_true[:,0]\n",
    "    y_pred_back= y_pred[:,0]\n",
    "    intersection_back= K.sum(y_true_back * y_pred_back)\n",
    "    back = (2. * intersection_back + smooth) / (K.sum(y_true_back) + K.sum(y_pred_back) + smooth)    \n",
    "    return back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef_spine(y_true, y_pred):\n",
    "    \n",
    "    y_true = K.reshape(y_true,(8*512*512,7))\n",
    "    y_pred = K.reshape(y_pred,(8*512*512,7))    \n",
    "    y_true_spine = y_true[:,1]\n",
    "    y_pred_spine= y_pred[:,1]\n",
    "    intersection_spine= K.sum(y_true_spine * y_pred_spine)\n",
    "    spine = (2. * intersection_spine + smooth) / (K.sum(y_true_spine) + K.sum(y_pred_spine) + smooth)\n",
    "    return spine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef_hips(y_true, y_pred):\n",
    "    \n",
    "    y_true = K.reshape(y_true,(8*512*512,7))\n",
    "    y_pred = K.reshape(y_pred,(8*512*512,7))    \n",
    "    y_true_hips = y_true[:,2]\n",
    "    y_pred_hips= y_pred[:,2]\n",
    "    intersection_hips= K.sum(y_true_hips * y_pred_hips)\n",
    "    hips = (2. * intersection_hips + smooth) / (K.sum(y_true_hips) + K.sum(y_pred_hips) + smooth)\n",
    "    return hips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef_sternum(y_true, y_pred):\n",
    "    \n",
    "    y_true = K.reshape(y_true,(8*512*512,7))\n",
    "    y_pred = K.reshape(y_pred,(8*512*512,7))    \n",
    "    y_true_sternum = y_true[:,3]\n",
    "    y_pred_sternum= y_pred[:,3]\n",
    "    intersection_sternum= K.sum(y_true_sternum * y_pred_sternum)\n",
    "    sternum = (2. * intersection_sternum + smooth) / (K.sum(y_true_sternum)+ K.sum(y_pred_sternum) + smooth)\n",
    "    return sternum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef_ribs(y_true, y_pred):\n",
    "    \n",
    "    y_true = K.reshape(y_true,(8*512*512,7))\n",
    "    y_pred = K.reshape(y_pred,(8*512*512,7))    \n",
    "    y_true_ribs = y_true[:,4]\n",
    "    y_pred_ribs= y_pred[:,4]\n",
    "    intersection_ribs= K.sum(y_true_ribs * y_pred_ribs)\n",
    "    ribs = (2. * intersection_ribs + smooth) / (K.sum(y_true_ribs) + K.sum(y_pred_ribs) + smooth)\n",
    "    return ribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef_sacrum(y_true, y_pred):\n",
    "    \n",
    "    y_true = K.reshape(y_true,(8*512*512,7))\n",
    "    y_pred = K.reshape(y_pred,(8*512*512,7))    \n",
    "    y_true_sacrum = y_true[:,5]\n",
    "    y_pred_sacrum= y_pred[:,5]\n",
    "    intersection_sacrum= K.sum(y_true_sacrum * y_pred_sacrum)\n",
    "    sacrum = (2. * intersection_sacrum + smooth) / (K.sum(y_true_sacrum) + K.sum(y_pred_sacrum) + smooth)\n",
    "    return sacrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef_femur(y_true, y_pred):\n",
    "    \n",
    "    y_true = K.reshape(y_true,(8*512*512,7))\n",
    "    y_pred = K.reshape(y_pred,(8*512*512,7))    \n",
    "    y_true_femur = y_true[:,6]\n",
    "    y_pred_femur= y_pred[:,6]\n",
    "    intersection_femur= K.sum(y_true_femur * y_pred_femur)\n",
    "    femur = (2. * intersection_femur + smooth) / (K.sum(y_true_femur) + K.sum(y_pred_femur) + smooth)\n",
    "    return femur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    \n",
    "    y_true_r = K.reshape(y_true,(8*512*512,7))\n",
    "    y_pred_r = K.reshape(y_pred,(8*512*512,7))\n",
    "    \n",
    "    y_true_bones = y_true_r[:,1:7]\n",
    "    y_pred_bones= y_pred_r[:,1:7]\n",
    "    \n",
    "    y_true_f_bones = K.flatten(y_true_bones)\n",
    "    y_pred_f_bones = K.flatten(y_pred_bones)\n",
    "    intersection_bones= K.sum(y_true_f_bones * y_pred_f_bones)\n",
    "    bones = (2. * intersection_bones + smooth) / (K.sum(y_true_f_bones) + K.sum(y_pred_f_bones) + smooth)\n",
    "    \n",
    "    return(bones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "class AdamLearningRateTracker(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        optimizer = self.model.optimizer\n",
    "        lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
    "        print('\\nLR: {:.9f}\\n'.format(lr))\n",
    "        \n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.e_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_epoch_end(self,batch,logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        numpy_loss_history = np.array(self.losses)\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(numpy_loss_history, label=\"loss\")\n",
    "        plt.ylabel('loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        numpy_val_loss_history = np.array(self.val_losses)\n",
    "        self.e_losses.append(logs.get(\"loss\"))\n",
    "        e_loss = np.array(self.e_losses)\n",
    "        \n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(e_loss, label=\"loss\")\n",
    "        plt.plot(numpy_val_loss_history, label=\"val_loss\")\n",
    "        plt.ylabel('loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "       \n",
    "import keras        \n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='Data/tensorboard', histogram_freq=1, write_graph=False, write_images=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def generator2(image_path, mask_path, batch_size):\n",
    "    sample=0\n",
    " \n",
    "    n_total= 15648\n",
    "    b=np.arange(0,15653) \n",
    "    a = np.random.choice(b,n_total, replace=False) \n",
    "   \n",
    "    while True:\n",
    "        image = np.zeros((batch_size, 512, 512,1))\n",
    "        mask = np.zeros((batch_size, 512, 512,1))\n",
    "        mask_c = np.zeros((batch_size, 512*512,7))\n",
    "        \n",
    "        for i in range(0, batch_size):\n",
    "            \n",
    "            if sample == n_total:\n",
    "                   sample=0\n",
    "                   a = np.random.choice(b,n_total, replace=False)\n",
    "        \n",
    "            index=a[sample]\n",
    "            image_name=\"O_\" +str(index)+ \".mhd\" #check name!\n",
    "            mask_name=\"M_\" +str(index)+ \".mhd\" #check name!\n",
    "     \n",
    "            img= sitk.ReadImage(os.path.join(image_path, image_name),sitk.sitkInt16)\n",
    "            img = sitk.GetArrayFromImage(img)\n",
    "            mas= sitk.ReadImage(os.path.join(mask_path, mask_name),sitk.sitkInt16)\n",
    "            mas = sitk.GetArrayFromImage(mas)\n",
    "\n",
    "            t = np.expand_dims(img, axis=3)\n",
    "            m = np.expand_dims(mas, axis=3)\n",
    "\n",
    "            \n",
    "            image[i]=t\n",
    "            mask[i]=m\n",
    "            sample+=1\n",
    "            \n",
    "            m=np.reshape(mask[i],(512*512))\n",
    "            mask_c[i] = to_categorical(m,7)\n",
    "            \n",
    "            image[i] -= np.mean(image[i])\n",
    "            image[i] /= np.std(image[i])\n",
    "\n",
    "        yield (image, mask_c)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Real-Time Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def generator(image_path, mask_path, batch_size):\n",
    "    sample=0\n",
    " \n",
    "    n_total= 15648\n",
    "    b=np.arange(0,15653) \n",
    "    a = np.random.choice(b,n_total, replace=False) \n",
    "   \n",
    "    while True:\n",
    "        image = np.zeros((batch_size, 512, 512,1))\n",
    "        mask = np.zeros((batch_size, 512, 512,1))\n",
    "        mask_c = np.zeros((batch_size, 512*512,7))\n",
    "        \n",
    "        for i in range(0, batch_size):\n",
    "            \n",
    "            if sample == n_total:\n",
    "                   sample=0\n",
    "                   a = np.random.choice(b,n_total, replace=False)\n",
    "        \n",
    "            index=a[sample]\n",
    "            image_name=\"O_\" +str(index)+ \".mhd\" #check name!\n",
    "            mask_name=\"M_\" +str(index)+ \".mhd\" #check name!\n",
    "     \n",
    "            img= sitk.ReadImage(os.path.join(image_path, image_name),sitk.sitkInt16)\n",
    "            img = sitk.GetArrayFromImage(img)\n",
    "            mas= sitk.ReadImage(os.path.join(mask_path, mask_name),sitk.sitkInt16)\n",
    "            mas = sitk.GetArrayFromImage(mas)\n",
    "     \n",
    "            #mas = to_categorical(mas,2)\n",
    "            t = np.expand_dims(img, axis=3)\n",
    "            m = np.expand_dims(mas, axis=3)\n",
    "            augmented=random_shift(t,m, 0.05, 0.05)\n",
    "            augmented=random_rotation(augmented[0],augmented[1],5)\n",
    "            augmented=random_zoom(augmented[0],augmented[1],(0.95,0.90))\n",
    "            \n",
    "            if np.random.random() < 0.5:\n",
    "                f = augmented\n",
    "                f =np.reshape(f,(2,512,512))\n",
    "                flipped=flip_axis(f[0],f[1])\n",
    "                flipped= np.expand_dims(flipped,axis=3)\n",
    "                augmented=flipped\n",
    "             \n",
    "            image[i]=augmented[0]\n",
    "            mask[i]=augmented[1]\n",
    "            sample+=1\n",
    "            \n",
    "            m=np.reshape(mask[i],(512*512))\n",
    "            mask_c[i] = to_categorical(m,7)\n",
    "            \n",
    "            image[i] -= np.mean(image[i])\n",
    "            image[i] /= np.std(image[i])\n",
    "            \n",
    "            \n",
    "            # VISUALIZE AUGMENTED IMAGES!\n",
    "            #y=np.reshape(image[i],(512,512))\n",
    "            #yy=np.reshape(mask[i],(512,512))\n",
    "            \n",
    "            #fig = plt.figure(figsize=(16, 12))\n",
    "            #z=fig.add_subplot(1,4,1)\n",
    "            #imgplot1 = plt.imshow(img, cmap=\"gray\")\n",
    "            #zz=fig.add_subplot(1,4,2)\n",
    "            #imgplot2 = plt.imshow(mas, cmap=\"gray\")\n",
    "            #zzz=fig.add_subplot(1,4,3)\n",
    "            #imgplot1 = plt.imshow(y, cmap=\"gray\")\n",
    "            #zzzz=fig.add_subplot(1,4,4)\n",
    "            #imgplot2 = plt.imshow(yy, cmap=\"gray\")\n",
    "            \n",
    "            \n",
    "       \n",
    "        yield (image, mask_c)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def generator_val(batch_size):\n",
    "    sample=0\n",
    "    path=\"Train/2DIm/Validation/\"\n",
    "    n_total=424 \n",
    "    b=np.arange(0,425) \n",
    "    a = np.random.choice(b,n_total, replace=False) \n",
    "   \n",
    "    while True:\n",
    "        \n",
    "        image = np.zeros((batch_size, 512, 512,1))\n",
    "        mask = np.zeros((batch_size, 512*512,7))\n",
    "        \n",
    "        for i in range(0, batch_size):\n",
    "            if sample == n_total:\n",
    "                   sample=0\n",
    "                   a = np.random.choice(b,n_total, replace=False)\n",
    "        \n",
    "          \n",
    "            index=a[sample]\n",
    "     \n",
    "            image_name=\"O/O_\" +str(index)+ \".mhd\" #check name!\n",
    "            mask_name=\"M/M_\" +str(index)+ \".mhd\" #check name!\n",
    "     \n",
    "            img= sitk.ReadImage(os.path.join(path, image_name),sitk.sitkInt16)\n",
    "            img = sitk.GetArrayFromImage(img)\n",
    "            mas= sitk.ReadImage(os.path.join(path, mask_name),sitk.sitkInt16)\n",
    "            mas = sitk.GetArrayFromImage(mas)\n",
    "     \n",
    "            mas=np.reshape(mas,(512*512))\n",
    "            mask[i] = to_categorical(mas,7)\n",
    "            image[i] = np.expand_dims(img, axis=3)\n",
    "            \n",
    "            image[i] -= np.mean(image[i])\n",
    "            image[i] /= np.std(image[i])\n",
    "            sample+=1\n",
    "        \n",
    "        yield (image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from keras.callbacks import History \n",
    "from keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def train_and_predict():\n",
    "    \n",
    "    steps_per_epoch=1956 # = number of sample / batch size\n",
    "    val_steps=53\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    #model.load_weights('Models/Last/unet.h5')\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint('Models/Last/unet1.h5', monitor='loss', save_weights_only=False, save_best_only=False)\n",
    "    history = History()\n",
    "    history_loss = LossHistory()\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "\n",
    "    model.fit_generator(generator2(\"../Orig2D\",\"../FinalMasks2D\",8), steps_per_epoch=steps_per_epoch, epochs=100, max_q_size=4, verbose=1, initial_epoch=0, callbacks=[model_checkpoint,history, history_loss, AdamLearningRateTracker()])\n",
    "\n",
    "    #TQDMNotebookCallback()\n",
    "        \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "    #plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.ylabel('error')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.title('training error')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "train_and_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Testing the trained model\n",
    "\n",
    "model = get_unet()\n",
    "model.load_weights('../Models/unet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Load scan converted to a numpy array\n",
    "\n",
    "t= np.load('../Data/E1.npy')\n",
    "t = np.expand_dims(t, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "image_t = model.predict(t, batch_size=6, verbose=1)\n",
    "print(image_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Select class image to save\n",
    "\n",
    "image_t=np.reshape(image_t,(512,512,7))\n",
    "spine=image_t[:,:,2] #select class\n",
    "np.save('../Test/spine.npy', spine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}